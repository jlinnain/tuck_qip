{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:red'>Quantitative Investing with Python</span>\n",
    "\n",
    "### Professor Juhani Linnainmaa\n",
    "\n",
    "Dartmouth College and Kepos Capital\n",
    "\n",
    "*Last revised:* January 22, 2025\n",
    "\n",
    "--- \n",
    "\n",
    "# **Topic 5:** Portfolio Optimization\n",
    "\n",
    "One of the main goals in investments and trading is to maximize the Sharpe ratio\n",
    "\n",
    "Much of the discussion in investments is about this portfolio choice problem:\n",
    "\n",
    "- We want to diversity across many assets\n",
    "  - Diversification helps when assets are not perfectly correlated\n",
    "\n",
    "- We would love to find assets that:\n",
    "\n",
    "  1. Have high expected returns\n",
    "  2. Have low standard deviation of returns\n",
    "  3. Have low or negative correlation with other assets\n",
    "\n",
    "- The same ideas apply to trading as well\n",
    "  - Think of factors and signals as \"assets\"\n",
    "  \n",
    "#### <span style='color:red'>These topics are discussed *a lot* in the Investments class!</span>\n",
    "\n",
    "- Portfolio *optimization* is important in quantitative finance\n",
    "\n",
    "\n",
    "#### Plan \n",
    "\n",
    "1. Visualizing the investment opportunity set\n",
    "2. Finding the optimal (= maximum Sharpe ratio) portfolio\n",
    "3. Measuring the performance of the equal-weighted and optimal portfolio in \"training\" and \"validation\" samples\n",
    "4. Improving optimization\n",
    "   - Shrinkage\n",
    "   - Machine-learning approach to optimal shrinkage (**a more general point about the train-validate-test paradigm**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements\n",
    "\n",
    "One new package that we are using here is **scipy**\n",
    "\n",
    "- We use it to find optimal portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "from io import BytesIO, StringIO\n",
    "import zipfile\n",
    "\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for downloading Ken French data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_french_data(url=None, csvname=None, skiplines=None):\n",
    "    \n",
    "    response = requests.get(url)\n",
    "\n",
    "    # If the request is NOT successful, raise an exception\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to download zip file. Status code: {response.status_code}\")\n",
    "\n",
    "    with zipfile.ZipFile(BytesIO(response.content)) as zip_file:\n",
    "\n",
    "        # Check if the file exists in the zip archive\n",
    "        if csvname in zip_file.namelist():\n",
    "            # Read the CSV file directly from the zip archive\n",
    "            with zip_file.open(csvname) as csv_file:\n",
    "                lines = csv_file.readlines()\n",
    "\n",
    "            # Remove rows from the beginning\n",
    "            lines = lines[skiplines:]\n",
    "\n",
    "            # Create a DataFrame from the trimmed lines using StringIO\n",
    "            # First need to decode byte strings into unicode\n",
    "            lines = [line.decode(\"utf-8\") for line in lines]\n",
    "\n",
    "            # at some point the file switches from monthly factors to annual factors and other stuff\n",
    "            # we can delete what ever comes after\n",
    "            for idx, line in enumerate(lines):\n",
    "                if ('Annual Factors' in line) or (len(line.strip())==0): break\n",
    "                \n",
    "            lines = lines[:idx]\n",
    "            clean_csv = '\\n'.join(lines)\n",
    "            df = pd.read_csv(StringIO(clean_csv))   \n",
    "            \n",
    "            # convert date into a format we understand and make it the index\n",
    "            # also convert returns from percentages (e.g., 2.12) to decimles (e.g., 0.0212) by dividing by 100\n",
    "            df['date'] = df['Unnamed: 0'].apply(lambda x: datetime.strptime(str(x), '%Y%m'))\n",
    "            df = df.drop(columns='Unnamed: 0')\n",
    "            df = df.set_index('date') / 100\n",
    "\n",
    "            print(f'File {csvname} read successfully!')\n",
    "            return df\n",
    "        else:\n",
    "            print(f'Zip file found but file {csvname} not found in the archive.')   \n",
    "            return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data for 30 industry portfolios from Ken French's website\n",
    "\n",
    "I also merge the risk-free rate into these data from Topic 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file we want to read -- the CSV file inside has almost the same name \n",
    "url = 'https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/30_Industry_Portfolios_CSV.zip'\n",
    "csvname = '30_Industry_Portfolios.CSV'\n",
    "\n",
    "ind_data = download_french_data(url=url, csvname=csvname, skiplines=11)\n",
    "industries = ind_data.columns.to_list()\n",
    "n_industries = len(industries)\n",
    "\n",
    "# open ff_data.pkl from Topic 3 and copy over RF column\n",
    "ff_data = pd.read_pickle('/home/jovyan/data/ff_data.pkl')\n",
    "ind_data = ind_data.merge(ff_data['RF'], left_index=True, right_index=True, how='left')\n",
    "ind_data = ind_data.loc['1963-07':]\n",
    "ind_data.to_pickle('/home/jovyan/data/ind_data.pkl')\n",
    "\n",
    "print('\\nData:\\n')\n",
    "print(ind_data.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into three parts: \"training data\", \"validation data\", and \"test date\"\n",
    "\n",
    "- I'll explain these terms in class\n",
    "  - They are *very* central to machine/statistical learning\n",
    "- I also record, separately, the risk-free rate for these three periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ind_data.loc[:'2000-12', industries]\n",
    "train_rf = ind_data.loc[:'2000-12', 'RF']\n",
    "\n",
    "val_data = ind_data.loc['2001-01':'2015-12', industries]\n",
    "val_rf = ind_data.loc['2001-01':'2015-12', 'RF']\n",
    "\n",
    "test_data = ind_data.loc['2016-01':'2023-12', industries]\n",
    "test_rf = ind_data.loc['2016-01':'2023-12', 'RF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"text-align: center; font-family: 'Georgia', sans-serif; font-size: 36px; font-weight: bold; color: red;\">\n",
    "    Visualizing the investment opportunity set\n",
    "</div>\n",
    "\n",
    "- Investment opportunity set is the \"possibility of investments\" we *could* make\n",
    "  - If you have 100 assets, there are MANY (infinitely many) different portfolios you could construct<br><br>\n",
    "  \n",
    "  \n",
    "- If we take the view that we care about expected returns and volatilities, we can characterize every portfolio with just two numbers:\n",
    "  \n",
    "  1. Expected return\n",
    "  2. Volatility<br><br>\n",
    "  \n",
    "  \n",
    "- Let's take five industries and create N random portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10_000\n",
    "k = 5\n",
    "\n",
    "simulation_results = []\n",
    "\n",
    "for i in range(N):\n",
    "    \n",
    "    # draw random weights from the standard normal distribution\n",
    "    weights = np.random.normal(loc=0.0, scale=1.0, size=k)\n",
    "    weights /= np.sum(weights)\n",
    "    \n",
    "    # returns on the portfolio\n",
    "    portfolio_return = train_data.iloc[:,:k].dot(weights)\n",
    "    \n",
    "    # compute annualized mean and standard deviation and append to the results-list\n",
    "    simulation_results.append({'mean': 12 * portfolio_return.mean(), 'std': np.sqrt(12) * portfolio_return.std()})\n",
    "\n",
    "# convert list into a DataFrame\n",
    "simulation_results = pd.DataFrame(simulation_results)\n",
    "\n",
    "# remove high-vol portfolios\n",
    "simulation_results = simulation_results[simulation_results['std']<1]\n",
    "N = len(simulation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_results.iloc[:100].plot.scatter(x='std', y='mean', title='100 random portfolios', xlabel='Volatility', ylabel='Average Return', figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_results.plot.scatter(x='std', y='mean', title=f'{N:,} random portfolios', figsize=(12,8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis function from Topic 2\n",
    "\n",
    "- Computes and reports Sharpe ratio\n",
    "  - If $r_f$ is provided, subtract it from returns\n",
    "- Plots cumulative returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_returns(r=None, rf=None, title=''):\n",
    "    if rf is not None:\n",
    "        sharpe_ratio = np.sqrt(12) * (r.mean() - rf) / r.std()\n",
    "    else:\n",
    "        sharpe_ratio = np.sqrt(12) * r.mean() / r.std()\n",
    "    print(f'Strategy: {title}')\n",
    "    print(f'Sharpe ratio: {sharpe_ratio:.2f}')\n",
    "    r.cumsum().plot(figsize=(12,8), title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"text-align: center; font-family: 'Georgia', sans-serif; font-size: 36px; font-weight: bold; color: red;\">\n",
    "    An equal-weighted portfolio of 30 industries in training sample\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_equal = np.array(len(industries) * [1. / len(industries)])\n",
    "train_portfolio_return_equal = train_data.mul(weights_equal).sum(axis=1)\n",
    "analyze_returns(r=train_portfolio_return_equal, rf=train_rf.mean(), title='1/N Strategy in Training Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"text-align: center; font-family: 'Georgia', sans-serif; font-size: 36px; font-weight: bold; color: red;\">\n",
    "    Mean-variance efficient portfolio in the training sample\n",
    "</div>\n",
    "\n",
    "\n",
    "- I first optimize numerically using returns themselves\n",
    "- ```Optimization``` is the same as using Excel's solver\n",
    "- We need to specify a few things:\n",
    "  - A function that returns a value we are *minimizing* (in Excel, we can just point to a cell that has the right formula; here, the function is the formula)\n",
    "    - The function can also accept other arguments\n",
    "  - What are the initial guesses for the solution\n",
    "  - What algorithm we use to minimize\n",
    "  - What constraints (e.g., the weights add up to zero) do we have\n",
    "  - Are there any bounds for the choice variables (e.g., weights need to be positive?)\n",
    "\n",
    "#### Note:\n",
    "\n",
    "- This might look a bit overwhelming, but just think about it as setting up the solver\n",
    "- The steps are always the same\n",
    "- If you need to solve a completely different problem, you would pretty much just copy the code, modify a few things, and you'd be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes and returns the NEGATIVE of the Sharpe ratio because optimization function *minimize*\n",
    "\n",
    "def neg_sharpe_ratio(weights, df, rf):\n",
    "    portfolio_return = df.mul(weights).sum(axis=1)\n",
    "    sharpe_ratio = np.sqrt(12) * (portfolio_return.mean() - rf) / portfolio_return.std()\n",
    "    return -sharpe_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a constraint: it is an EQuality constraint that sets the sum of weights to 1\n",
    "constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})  \n",
    "\n",
    "# Start from an equal-weighted portfolio \n",
    "results = minimize(neg_sharpe_ratio, weights_equal, args=(train_data, train_rf.mean()), method='SLSQP', constraints=constraints)\n",
    "\n",
    "weights_optimal = results['x']\n",
    "\n",
    "print('Optimal weights in percentages (%)')\n",
    "pd.Series(100*weights_optimal, index=industries).sort_values().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portfolio_return_optimal = train_data.mul(weights_optimal).sum(axis=1)\n",
    "analyze_returns(r=train_portfolio_return_optimal, rf=train_rf.mean(), title='Optimal Portfolio in the Training Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do we stand?\n",
    "\n",
    "- We have looked at data from 1960s to 2010\n",
    "- An equal-weighted portfolio of the 30 industries has a Sharpe ratio of 0.42\n",
    "- A mean-variance efficient portfolio has a Sharpe ratio of 0.90\n",
    "\n",
    "# <span style='color:red'>Question</span>: Which portfolio would you prefer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"text-align: center; font-family: 'Georgia', sans-serif; font-size: 36px; font-weight: bold; color: red;\">\n",
    "    Mean-variance efficient portfolio in the VALIDATION sample\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_portfolio_return_equal = val_data.mul(weights_equal).sum(axis=1)\n",
    "analyze_returns(r=val_portfolio_return_equal, rf=val_rf.mean(), title='1/N Strategy in the Validation Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_portfolio_return_optimal = val_data.mul(weights_optimal).sum(axis=1)\n",
    "analyze_returns(r=val_portfolio_return_optimal, rf=val_rf.mean(), title='Optimal Portfolio in the Validation Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br>\n",
    "<div style=\"text-align: center; font-family: 'Georgia', sans-serif; font-size: 36px; font-weight: bold; color: red;\">\n",
    "    Optimizing based on expected returns and covariances\n",
    "</div>\n",
    "\n",
    "- We don't need to have the full \"historical data\" to do optimization\n",
    "- The optimal portfolio depends on three inputs:\n",
    "  - Expected returns, variances, and covariances\n",
    "- If we *have* historical data -- and we assume that these data are representative of future data -- we can do the optimization as before\n",
    "- But we will also get identical results if we computed average returns, variances, and covariances, and optimize using them instead\n",
    "- There is some portfolio mathematics for this\n",
    "  - The function \"neg_sharpe_ratio2\" is almost the same as before but it now accepts just the mean returns (30 numbers) and the covariance matrix (30x30 numbers) plus the risk-free rate\n",
    "- There are great benefits to doing the optimization like this because now we can modify the inputs to get more sensible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Sharpe ratio calculation\n",
    "def neg_sharpe_ratio2(weights, mean_returns, cov_matrix, rf):\n",
    "    portfolio_return = np.dot(mean_returns, weights)\n",
    "    portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    sharpe_ratio = (portfolio_return - rf) / portfolio_volatility\n",
    "    return -sharpe_ratio  # Negative for minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization constraints\n",
    "constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})  # The sum of weights is 1\n",
    "\n",
    "mean_returns = train_data.mean()\n",
    "cov_matrix = train_data.cov()\n",
    "\n",
    "# Start from an equal-weighted portfolio but then maximize Sharpe ratio\n",
    "results = minimize(neg_sharpe_ratio2, weights_equal, args=(mean_returns, cov_matrix, train_rf.mean()), method='SLSQP', constraints=constraints)\n",
    "weights_optimal = results['x']\n",
    "train_portfolio_return_optimal = train_data.mul(weights_optimal).sum(axis=1)\n",
    "analyze_returns(r=train_portfolio_return_optimal, rf=train_rf.mean(), title='Optimal Portfolio in the Training Sample (This Should be the Same as Before!)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A helper function for shrinking average returns and covariance matrix estimates to make them less noisy\n",
    "\n",
    "- 'shrinkage' in statistics is about pulling estimates towards some prior\n",
    "- E.g., if you think that some correlations are noise, you might want to pull correlations towards zero. \n",
    "  - In the code below, I multiple the off-diagonal elements by some number <1\n",
    "- Similarly, I make the mean returns more similar to each other (I shrink them towards the overall mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cov_matrix(df: pd.DataFrame, shrink_pct: float = 0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the covariance matrix of the given DataFrame and optionally shrink\n",
    "    off-diagonal elements by 'shrink_pct'.\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        raise ValueError(\"df cannot be None.\")\n",
    "\n",
    "    if not (0 <= shrink_pct <= 1):\n",
    "        raise ValueError(f\"Invalid shrink_pct={shrink_pct}. Must be between 0 and 1.\")\n",
    "\n",
    "    cov = df.cov()\n",
    "\n",
    "    if shrink_pct > 0:\n",
    "        # Create a mask for diagonal elements\n",
    "        diagonal_mask = np.eye(len(cov), dtype=bool)\n",
    "        # Scale only off-diagonal elements by (1 - shrink_pct)\n",
    "        cov.values[~diagonal_mask] *= (1 - shrink_pct)\n",
    "\n",
    "    return cov\n",
    "\n",
    "def compute_mean_returns(df=None, shrink_pct=0):\n",
    "    mean = df.mean()\n",
    "    if shrink_pct > 1:\n",
    "        raise ValueError(f'{shrink_pct=} invalid. Express shrink_pct as a number between 0 and 1')\n",
    "    if shrink_pct > 0:\n",
    "        overall_mean = mean.mean()\n",
    "        mean = (1 - shrink_pct) * mean + shrink_pct * overall_mean\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's recompute the optimal portfolio after shrinking both the means and covariances by 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_returns = compute_mean_returns(train_data, 0.2)\n",
    "cov_matrix = compute_cov_matrix(train_data, 0.2)\n",
    "\n",
    "# Start from an equal-weighted portfolio but then maximize Sharpe ratio\n",
    "results = minimize(neg_sharpe_ratio2, weights_equal, args=(mean_returns, cov_matrix, train_rf.mean()), method='SLSQP', constraints=constraints)\n",
    "weights_optimal = results['x']\n",
    "train_portfolio_return_optimal = train_data.mul(weights_optimal).sum(axis=1)\n",
    "analyze_returns(r=train_portfolio_return_optimal, rf=train_rf.mean(), title='Refined Optimal Portfolio in the Training Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_portfolio_return_optimal = val_data.mul(weights_optimal).sum(axis=1)\n",
    "analyze_returns(r=val_portfolio_return_optimal, rf=val_rf.mean(), title='Refined Optimal Portfolio in the Validation Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Optimal weights in percentages (%)')\n",
    "pd.Series(100*weights_optimal, index=industries).sort_values().round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"text-align: center; font-family: 'Georgia', sans-serif; font-size: 36px; font-weight: bold; color: red;\">\n",
    "    Machine Learning Approach to Finding the Optimal Shrinkage\n",
    "</div>\n",
    "\n",
    "- The key idea in machine learning is the **Train-Validate-Test** paradigm\n",
    "- I implement it using our training data/validation date split\n",
    "  - The **idea** is the key, not the specific implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "shrinkage_grid = np.arange(0.0, 1.1, 0.1)\n",
    "\n",
    "search_results = []\n",
    "\n",
    "for mean_shrinkage in tqdm(shrinkage_grid):\n",
    "    for cov_shrinkage in shrinkage_grid:\n",
    "        \n",
    "        mean_returns = compute_mean_returns(train_data, mean_shrinkage)\n",
    "        cov_matrix = compute_cov_matrix(train_data, cov_shrinkage)\n",
    "\n",
    "        results = minimize(neg_sharpe_ratio2, weights_equal, args=(mean_returns, cov_matrix, train_rf.mean()), method='SLSQP', constraints=constraints)\n",
    "        weights_optimal = results['x']\n",
    "\n",
    "        val_portfolio_return = val_data.mul(weights_optimal).sum(axis=1)\n",
    "        sharpe = np.sqrt(12) * (val_portfolio_return.mean() - val_rf.mean()) / val_portfolio_return.std()\n",
    "        \n",
    "        search_results.append({'mean_shrinkage': mean_shrinkage, 'cov_shrinkage': cov_shrinkage, 'val_sharpe': sharpe})\n",
    "        \n",
    "search_results = pd.DataFrame(search_results).sort_values('val_sharpe').set_index(['mean_shrinkage', 'cov_shrinkage'])\n",
    "search_results        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "best_shrinkages = search_results.iloc[-1].name\n",
    "\n",
    "mean_returns = compute_mean_returns(train_data, best_shrinkages[0])\n",
    "cov_matrix = compute_cov_matrix(train_data, best_shrinkages[1])\n",
    "\n",
    "# Start from an equal-weighted portfolio but then maximize Sharpe ratio\n",
    "results = minimize(neg_sharpe_ratio2, weights_equal, args=(mean_returns, cov_matrix, train_rf.mean()), method='SLSQP', constraints=constraints)\n",
    "weights_optimal = results['x']\n",
    "\n",
    "train_portfolio_return = train_data.mul(weights_optimal).sum(axis=1)\n",
    "validation_portfolio_return = val_data.mul(weights_optimal).sum(axis=1)\n",
    "test_portfolio_return = test_data.mul(weights_optimal).sum(axis=1)\n",
    "\n",
    "analyze_returns(r=train_portfolio_return, rf=train_rf.mean(), title='Optimized Portfolio in the Training Sample')\n",
    "plt.show()\n",
    "\n",
    "analyze_returns(r=validation_portfolio_return, rf=val_rf.mean(), title='Optimized Portfolio in the Validation Sample')\n",
    "plt.show()\n",
    "\n",
    "analyze_returns(r=test_portfolio_return, rf=test_rf.mean(), title='Optimized Portfolio in the Test Sample')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
