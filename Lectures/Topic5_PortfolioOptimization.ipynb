{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:red'>Quantitative Investing with Python</span>\n",
    "\n",
    "### Professor Juhani Linnainmaa\n",
    "\n",
    "Dartmouth College (George J. Records Professor of Investments) and Kepos Capital (Co-Director of Research)\n",
    "\n",
    "*Last revised:* January 23, 2024\n",
    "\n",
    "--- \n",
    "\n",
    "# **Topic 5:** Portfolio Optimization\n",
    "\n",
    "One of the main goals in investments in to maximize Sharpe ratio\n",
    "\n",
    "- There may be other considerations such as preferences, taxes, liquidity,... but the idea of earning the highest return given the amount of risk you're taking is a good starting point\n",
    "\n",
    "Much of the discussion in investments is about this portfolio choice problem:\n",
    "\n",
    "- We want to diversity across many assets\n",
    "  - Diversification helps when assets are not perfectly correlated\n",
    "\n",
    "\n",
    "- We would love to find assets that:\n",
    "\n",
    "  1. Have high expected returns\n",
    "  2. Have low standard deviation of returns\n",
    "  3. Have low or negative correlation with other assets\n",
    "  \n",
    "  (If we consider long-short portfolios, we can also flip the signs of (1) and (3) around.)\n",
    "\n",
    "#### <span style='color:red'>These topics are discussed *a lot* in the Investments class!</span>\n",
    "\n",
    "- Portfolio *optimization* is important in quantitative finance\n",
    "\n",
    "- If you have a signal that predicts differences in asset returns -- e.g., past returns (short-term reversals and momentum), book-to-market, etc. -- you would still likely want to consider how different assets are correlated and how volatile they are\n",
    "  - Suppose you are a value investor and that there are two stocks, A and B, that both have a book-to-market ratio of 1\n",
    "  - Stock A has high volatility and is highly correlated with other assets\n",
    "  - Stock B has low volatility and is negative correlated with other assets\n",
    "  - In this case we would probably want to invest more in stock B than stock A\n",
    "    \n",
    "#### Plan -- The discussion in these notes is about:**\n",
    "\n",
    "1. Visualizing the investment opportunity set\n",
    "   - What are we trying to do?\n",
    "2. Finding the optimal (=maximum Sharpe ratio) portfolio\n",
    "3. Measuring the performance of the equal-weighted and optimal portfolio in \"training\" and \"validation\" samples\n",
    "4. Tips for improving optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements\n",
    "\n",
    "One new package that we are using here is **scipy**\n",
    "\n",
    "- We use it to find optimal portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "from io import BytesIO, StringIO\n",
    "import zipfile\n",
    "\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for downloading Ken French data (from Topic #2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_french_data(url=None, csvname=None, skiplines=None):\n",
    "    \n",
    "    response = requests.get(url)\n",
    "\n",
    "    # If the request is NOT successful, raise an exception\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to download zip file. Status code: {response.status_code}\")\n",
    "\n",
    "    with zipfile.ZipFile(BytesIO(response.content)) as zip_file:\n",
    "\n",
    "        # Check if the file exists in the zip archive\n",
    "        if csvname in zip_file.namelist():\n",
    "            # Read the CSV file directly from the zip archive\n",
    "            with zip_file.open(csvname) as csv_file:\n",
    "                lines = csv_file.readlines()\n",
    "\n",
    "            # Remove rows from the beginning\n",
    "            lines = lines[skiplines:]\n",
    "\n",
    "            # Create a DataFrame from the trimmed lines using StringIO\n",
    "            # First need to decode byte strings into unicode\n",
    "            lines = [line.decode(\"utf-8\") for line in lines]\n",
    "\n",
    "            # at some point the file switches from monthly factors to annual factors and other stuff\n",
    "            # we can delete what ever comes after\n",
    "            for idx, line in enumerate(lines):\n",
    "                if ('Annual Factors' in line) or (len(line.strip())==0): break\n",
    "                \n",
    "            lines = lines[:idx]\n",
    "            clean_csv = '\\n'.join(lines)\n",
    "            df = pd.read_csv(StringIO(clean_csv))   \n",
    "            \n",
    "            # convert date into a format we understand and make it the index\n",
    "            # also convert returns from percentages (e.g., 2.12) to decimles (e.g., 0.0212) by dividing by 100\n",
    "            df['date'] = df['Unnamed: 0'].apply(lambda x: datetime.strptime(str(x), '%Y%m'))\n",
    "            df = df.drop(columns='Unnamed: 0')\n",
    "            df = df.set_index('date') / 100\n",
    "\n",
    "            print(f'File {csvname} read successfully!')\n",
    "            return df\n",
    "        else:\n",
    "            print(f'Zip file found but file {csvname} not found in the archive.')   \n",
    "            return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data for 30 industry portfolios from Ken French's website\n",
    "\n",
    "I also merge the risk-free rate into these data from Topic 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file we want to read -- the CSV file inside has almost the same name \n",
    "url = 'https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/30_Industry_Portfolios_CSV.zip'\n",
    "csvname = '30_Industry_Portfolios.CSV'\n",
    "\n",
    "ind_data = download_french_data(url=url, csvname=csvname, skiplines=11)\n",
    "industries = ind_data.columns.to_list()\n",
    "n_industries = len(industries)\n",
    "\n",
    "# open ff_data.pkl from Topic 3 and copy over RF column\n",
    "ff_data = pd.read_pickle('Data/ff_data.pkl')\n",
    "ind_data = ind_data.merge(ff_data['RF'], left_index=True, right_index=True, how='left')\n",
    "ind_data = ind_data.loc['1963-07':]\n",
    "ind_data.to_pickle('data/ind_data.pkl')\n",
    "\n",
    "print('\\nData:\\n')\n",
    "print(ind_data.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into two parts: \"training data\" and \"validation data\"\n",
    "\n",
    "- I'll explain these terms in class\n",
    "  - They are *very* central to machine/statistical learning\n",
    "- I also record, separately, the risk-free rate for these two periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ind_data.loc[:'2010-12', industries]\n",
    "train_rf = ind_data.loc[:'2010-12', 'RF']\n",
    "\n",
    "val_data = ind_data.loc['2011-01':'2020-12', industries]\n",
    "val_rf = ind_data.loc['2011-01':'2020-12', 'RF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the investment opportunity set\n",
    "\n",
    "- Investment opportunity set is the \"possibility of investments\" we *could* make\n",
    "  - If you have 100 assets, there are MANY (infinitely many) different portfolios you could construct\n",
    "  \n",
    "  \n",
    "- If we take the view that we care about expected returns and volatilities, we can characterize every portfolio with just two numbers:\n",
    "  \n",
    "  1. Expected return\n",
    "  2. Volatility\n",
    "  \n",
    "  \n",
    "- Let's take five industries and create N random portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 25_000\n",
    "k = 5\n",
    "\n",
    "simulation_results = []\n",
    "\n",
    "for i in range(N):\n",
    "    \n",
    "    # draw random weights from a normal distribution\n",
    "    weights = np.random.uniform(0, 2, k)\n",
    "    weights /= np.sum(weights)\n",
    "    \n",
    "    # returns on the portfolio\n",
    "    portfolio_return = train_data.iloc[:,:k].dot(weights)\n",
    "    \n",
    "    # compute annualized mean and standard deviation and append to the results-list\n",
    "    simulation_results.append({'mean': 12 * portfolio_return.mean(), 'std': np.sqrt(12) * portfolio_return.std()})\n",
    "\n",
    "# convert list into a DataFrame\n",
    "simulation_results = pd.DataFrame(simulation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_results = pd.DataFrame(simulation_results)\n",
    "simulation_results.iloc[:100].plot.scatter(x='std', y='mean', title='100 random portfolios', figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_results.plot.scatter(x='std', y='mean', title=f'{N:,} random portfolios', figsize=(12,8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis function from Topic 2\n",
    "\n",
    "- Computes and reports Sharpe ratio\n",
    "  - If rf is provided, subtract it from returns\n",
    "- Plots cumulative returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_returns(r=None, rf=None, title=''):\n",
    "    if rf is not None:\n",
    "        sharpe_ratio = np.sqrt(12) * (r.mean() - rf) / r.std()\n",
    "    else:\n",
    "        sharpe_ratio = np.sqrt(12) * r.mean() / r.std()\n",
    "    print(f'Strategy: {title}')\n",
    "    print(f'Sharpe ratio: {sharpe_ratio:.2f}')\n",
    "    r.cumsum().plot(figsize=(12,8), title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An equal-weighted portfolio of 30 industries in training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_equal = np.array(len(industries) * [1. / len(industries)])\n",
    "train_portfolio_return_equal = train_data.mul(weights_equal).sum(axis=1)\n",
    "analyze_returns(r=train_portfolio_return_equal, rf=train_rf.mean(), title='1/N Strategy in Training Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean-variance efficient portfolio in the training sample\n",
    "\n",
    "- I first optimize numerically using returns themselves\n",
    "- Optimization is the same as using Excel's solver\n",
    "- We need to specify a few things:\n",
    "  - A function that returns a value that we are *minimizing* (in Excel, we can just point to a cell that has the right formula; here, the function is the formula)\n",
    "    - The function can also accept other arguments\n",
    "  - What are the initial guesses for the solution\n",
    "  - What algorithm we use to minimize\n",
    "  - What constraints (e.g., the weights add up to zero) do we have\n",
    "  - Are there any bounds for the choice variables (e.g., weights need to be positive?)\n",
    "\n",
    "#### Note:\n",
    "\n",
    "- This might look a bit overwhelming, but just think about it as setting up the solver\n",
    "- The steps are always the same\n",
    "- If you need to solve a completely different problem, you would pretty much just copy the code, modify a few things, and you'd be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes and returns the NEGATIVE of the Sharpe ratio because optimization function *minimize*\n",
    "\n",
    "def neg_sharpe_ratio(weights, df, rf):\n",
    "    portfolio_return = df.mul(weights).sum(axis=1)\n",
    "    sharpe_ratio = np.sqrt(12) * (portfolio_return.mean() - rf) / portfolio_return.std()\n",
    "    return -sharpe_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a constraint: it is an EQuality constraint that sets the sum of weights to 1\n",
    "constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})  \n",
    "\n",
    "# Start from an equal-weighted portfolio \n",
    "results = minimize(neg_sharpe_ratio, weights_equal, args=(train_data, train_rf.mean()), method='SLSQP', constraints=constraints)\n",
    "\n",
    "weights_optimal = results['x']\n",
    "\n",
    "print('Optimal weights in percentages (%)')\n",
    "pd.Series(100*weights_optimal, index=industries).sort_values().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portfolio_return_optimal = train_data.mul(weights_optimal).sum(axis=1)\n",
    "analyze_returns(r=train_portfolio_return_optimal, rf=train_rf.mean(), title='Optimal Portfolio in the Training Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do we stand?\n",
    "\n",
    "- We have looked at data from 1960s to 2010\n",
    "- An equal-weighted portfolio of the 30 industries has a Sharpe ratio of 0.42\n",
    "- A mean-variance efficient portfolio has a Sharpe ratio of 0.90\n",
    "\n",
    "### <span style='color:red'>Question</span>: Which portfolio would you prefer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the performance in the \"validation\" sample\n",
    "\n",
    "This is the sample that runs from 2011-01 to 2020-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_portfolio_return_equal = val_data.mul(weights_equal).sum(axis=1)\n",
    "analyze_returns(r=val_portfolio_return_equal, rf=val_rf.mean(), title='1/N Strategy in the Validation Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_portfolio_return_optimal = val_data.mul(weights_optimal).sum(axis=1)\n",
    "analyze_returns(r=val_portfolio_return_optimal, rf=val_rf.mean(), title='Optimal Portfolio in the Validation Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing, Part 2\n",
    "\n",
    "- We don't need to have the full \"historical data\" to do optimization\n",
    "- The optimal portfolio depends on three inputs:\n",
    "  - Expected returns, variances, and covariances\n",
    "- If we *have* historical data -- and we assume that these data are representative of future data -- we can do the optimization as before\n",
    "- But we will also get identical results if we computed average returns, variances, and covariances, and optimize using them instead\n",
    "- There is some portfolio mathematics for this\n",
    "  - The function \"neg_sharpe_ratio2\" is almost the same as before but it now accepts just the mean returns (30 numbers) and the covariance matrix (30x30 numbers) plus the risk-free rate\n",
    "- There are great benefits to doing the optimization like this because now we can modify the inputs to get more sensible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Sharpe ratio calculation\n",
    "def neg_sharpe_ratio2(weights, mean_returns, cov_matrix, rf):\n",
    "    portfolio_return = np.dot(mean_returns, weights)\n",
    "    portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    sharpe_ratio = (portfolio_return - rf) / portfolio_volatility\n",
    "    return -sharpe_ratio  # Negative for minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization constraints\n",
    "constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})  # The sum of weights is 1\n",
    "\n",
    "mean_returns = train_data.mean()\n",
    "cov_matrix = train_data.cov()\n",
    "\n",
    "# Start from an equal-weighted portfolio but then maximize Sharpe ratio\n",
    "results = minimize(neg_sharpe_ratio2, weights_equal, args=(mean_returns, cov_matrix, train_rf.mean()), method='SLSQP', constraints=constraints)\n",
    "weights_optimal = results['x']\n",
    "train_portfolio_return_optimal = train_data.mul(weights_optimal).sum(axis=1)\n",
    "analyze_returns(r=train_portfolio_return_optimal, rf=train_rf.mean(), title='Optimal Portfolio in the Training Sample (Same as Before)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A helper function for making the average returns and covariance matrix estimates less noisy\n",
    "\n",
    "- 'shrinkage' in statistics is about pulling estimates towards some prior\n",
    "- E.g., if you think that some correlations are noise, you might want to pull correlations towards zero. \n",
    "  - In the code below, I multiple the off-diagonal elements by some number <1\n",
    "- Similarly, I make mean returns more similar to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cov_matrix(df=None, shrink_pct=0):\n",
    "    cov = df.cov()\n",
    "    if shrink_pct > 1:\n",
    "        raise ValueError(f'{shrink_pct=} invalid. Express shrink_pct as a number between 0 and 1')\n",
    "    if shrink_pct > 0:\n",
    "        for col in cov.columns:\n",
    "            for row in cov.columns:\n",
    "                if col != row:\n",
    "                    cov.loc[row,col] *= (1-shrink_pct)\n",
    "    return cov\n",
    "\n",
    "def compute_mean_returns(df=None, shrink_pct=0):\n",
    "    mean = df.mean()\n",
    "    if shrink_pct > 1:\n",
    "        raise ValueError(f'{shrink_pct=} invalid. Express shrink_pct as a number between 0 and 1')\n",
    "    if shrink_pct > 0:\n",
    "        overall_mean = mean.mean()\n",
    "        mean = (1 - shrink_pct) * mean + shrink_pct * overall_mean\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "\n",
    "- In the optimization below, I still don't impose short-sale constraints\n",
    "- We could define:\n",
    "\n",
    "```\n",
    "bounds = tuple((0, 1) for _ in range(len(industries)))  \n",
    "```\n",
    "\n",
    "and then add an argument\n",
    "\n",
    "```\n",
    "bounds=bounds\n",
    "```\n",
    "\n",
    "to the minimize() function to have all weights be between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_returns = compute_mean_returns(train_data, 0.5)\n",
    "cov_matrix = compute_cov_matrix(train_data, 0.5)\n",
    "\n",
    "# Start from an equal-weighted portfolio but then maximize Sharpe ratio\n",
    "results = minimize(neg_sharpe_ratio2, weights_equal, args=(mean_returns, cov_matrix, train_rf.mean()), method='SLSQP', constraints=constraints)\n",
    "weights_optimal = results['x']\n",
    "train_portfolio_return_optimal = train_data.mul(weights_optimal).sum(axis=1)\n",
    "analyze_returns(r=train_portfolio_return_optimal, rf=train_rf.mean(), title='Refined Optimal Portfolio in the Training Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_portfolio_return_optimal = val_data.mul(weights_optimal).sum(axis=1)\n",
    "analyze_returns(r=val_portfolio_return_optimal, rf=val_rf.mean(), title='Refined Optimal Portfolio in the Validation Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Optimal weights in percentages (%)')\n",
    "pd.Series(100*weights_optimal, index=industries).sort_values().round(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
