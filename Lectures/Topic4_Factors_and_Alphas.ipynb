{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:red'>Quantitative Investing with Python</span>\n",
    "\n",
    "### Professor Juhani Linnainmaa\n",
    "\n",
    "Dartmouth College and Kepos Capital\n",
    "\n",
    "*Last revised:* January 20, 2025\n",
    "\n",
    "--- \n",
    "\n",
    "# **Topic 4:** Replicating Academic Factors and Measuring Alphas\n",
    "\n",
    "1. We will merge accounting data from Compustat and stock data from CRSP\n",
    "   - I'll use the processed CRSP file we created and saved previously\n",
    "   - By having the merged dataset, we can construct factors such as HML, which is based on sorting stocks into portfolios by their book-to-market ratios<br><br>\n",
    "\n",
    "\n",
    "2. I provide some general code for constructing factors based on arbitrary signals, such as BE/ME or the signal underneath the momentum factor \n",
    "   - I'll be more careful in my replicating than what I did with the short-term reversals factor\n",
    "   - There are some more details. These are not *that* important in practice, but it is useful to think about them---at the very least, we highlight the fact that many decisions go into constructing trading strategies / factors<br><br>\n",
    "\n",
    "\n",
    "3. We will then estimate linear regression to assess strategies'/factors' alphas in asset pricing models such as the Capital Asset Pricing model or the Fama-French five-factor model\n",
    "   - I'll use the same Fama-French factors we downloaded and pickled previously\n",
    "   - I'll discuss the meaning of alphas in class, not on this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import requests\n",
    "from io import BytesIO, StringIO\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"text-align: center; font-family: 'Georgia', sans-serif; font-size: 36px; font-weight: bold; color: red;\">\n",
    "    Read and process annual fundamentals from Compustat\n",
    "</div>\n",
    "\n",
    "- Compustat is a well-known provider of fundamental data\n",
    "  - Fundamental in this context means accounting data, that is, income statement and balance sheet information\n",
    "- I downloaded all data for U.S. firms. I look at *annual* reports, which is still the standard in academic literature\n",
    "  - The same ideas of course apply if we use quarterly data or any other data sources (such as CapitalIQ or Datastream) besides Compustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compustat_url = 'https://dl.dropboxusercontent.com/scl/fi/vd2ci1fw093kbx9375m2z/Compustat_September2023.csv.zip?rlkey=g68xz4deyiq5n7cx5n7q1ma0u'\n",
    "response = requests.get(compustat_url)\n",
    "with zipfile.ZipFile(BytesIO(response.content)) as z:\n",
    "    with z.open('Compustat_September2023.csv') as f:\n",
    "        df = pd.read_csv(f)\n",
    "\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the data a bit\n",
    "\n",
    "1. Rename the stock identifier variable to be consistent with the CRSP name\n",
    "2. Compute the book value of equity using the Fama-French definition\n",
    "   - Fama and French (1993) don't provide all the details\n",
    "   - Cohen, Polk, and Vuolteenaho (2003), who were Ph.D. students at Chicago, write:\n",
    "   \n",
    "     > Book equity is defined as the stockholders' equity, plus balance sheet deferred taxes (data item 74) and investment tax credit (data item 208; if available), plus postretirement benefit liabilities (data item 330; if available), minus the book value of preferred stock. Depending on availability, we use redemption (data item 56), liquidation (data item 10), or par value (data item 130) in that order for the book value of preferred stock. Stockholders' equity used in the above formula is calculated as follows. We prefer the stockholders' equity number reported by Moody's or COMPUSTAT (data item 216). If neither one is available, we measure stockholders' equity as the book value of common equity (data item 60), plus the par value of preferred stock. (Note that the preferred stock is added at this stage, because it is later subtracted in the book equity formula.) If common equity is not available, we compute stockholders' equity as the book value of assets (data item 6) minus total liabilities (data item 181), all from COMPUSTAT.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename stock identifier to be consistent with CRSP\n",
    "df = df.rename(columns = {'LPERMNO': 'permno'})\n",
    "df['datadate'] = pd.to_datetime(df['datadate'], format='%Y-%m-%d').dt.to_period('M').dt.to_timestamp()\n",
    "df = df.set_index(['permno', 'datadate'])\n",
    "\n",
    "# compute book value of equity using the Fama-French rules\n",
    "be = df['seq'].combine_first(df['ceq'] + df['pstk']).combine_first(df['at'] - df['lt'])\n",
    "\n",
    "# 1. compute preferred stock\n",
    "pref = df['pstkrv'].combine_first(df['pstkl']).combine_first(df['pstk'])\n",
    "\n",
    "# 2. adjust book value of equity for preferred stock (if exists)\n",
    "pref_not_missing = pref.notnull()\n",
    "be.loc[pref_not_missing] -= pref\n",
    "\n",
    "# 3. investment tax credit (only for fiscal years ending in 1993 or before)\n",
    "df['txditc'] = df['txditc'].replace({np.nan: 0})\n",
    "before_1993 = df.index.get_level_values('datadate') <= '1993-12'\n",
    "be.loc[before_1993] += df.loc[before_1993, 'txditc']\n",
    "\n",
    "df['be'] = be\n",
    "\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep only the necessary data\n",
    "\n",
    "- PERMNO and datadate (which are in the index)\n",
    "- at (total assets)\n",
    "- sale (revenue) and cogs (cost of goods sold)\n",
    "- be (book value of equity)\n",
    "- **Note:** I don't use at, sale, and cogs on this notebook, but I'll leave them in for reasons to be discussed in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_vars = ['at', 'sale', 'cogs', 'be']\n",
    "\n",
    "compustat = df[['at', 'sale', 'cogs', 'be']].copy().dropna(how='all')\n",
    "compustat.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CRSP data from Topic #3 and filter Compustat data so that it only includes the PERMNOs we have in the CRSP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_crsp = pd.read_pickle('/home/jovyan/data/crsp.pkl')\n",
    "cs_crsp = cs_crsp.reset_index(level='date')\n",
    "cs_crsp = cs_crsp.set_index('date', append=True)\n",
    "display(cs_crsp.tail(5))\n",
    "\n",
    "ok = compustat.index.get_level_values('permno').isin(cs_crsp.index.get_level_values('permno').unique())\n",
    "print(f'Compustat shape before filtering: {compustat.shape}')\n",
    "compustat = compustat[ok]\n",
    "print(f'Compustat shape after filtering: {compustat.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"text-align: center; font-family: 'Georgia', sans-serif; font-size: 36px; font-weight: bold; color: red;\">\n",
    "    Merge Compustat data with CRSP\n",
    "</div>\n",
    "\n",
    "- We have monthly stocks returns but *annual* Compustat data\n",
    "- Moreover, Compustat data is reported *not* when the information is available to investors but by fiscal-year ends\n",
    "  - Variable ```datadate``` tells the end date of the fiscal year\n",
    "- **THIS IS A PROBLEM!**\n",
    "  - I need to lag Compustat data appropriately relative to CRSP\n",
    "  - What does this mean? \n",
    "    - Companies announce their earnings with some lag \n",
    "    - A conservative assumption from Fama-French is that accounting data from a fiscal year that ended in year t is available at the end of June in year t+1\n",
    "  - We could do this in many different ways but I use the following logic:\n",
    "    1. Reindex Compustat data so that we have data for all months over which the same stock is present in either CRSP or Compustat\n",
    "    2. Lag fundamental information by six months (the Fama-French assumption)\n",
    "    3. Forward will the data for up to 23 months\n",
    "- We now have monthly observations that we can merge directly with CRSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename Compustat datadate variable to 'date'\n",
    "compustat = compustat.rename_axis(index={'datadate': 'date'})\n",
    "\n",
    "# reindex Compustat data to cover all dates seen in Compustat and CRSP \n",
    "cs_index = compustat.index\n",
    "crsp_index = cs_crsp.index\n",
    "combined_index = cs_index.union(crsp_index)\n",
    "compustat = compustat.reindex(combined_index)\n",
    "\n",
    "# there might be some gaps in dates\n",
    "# in the code below, I create an index that covers every month from the first time we see a firm to the last time\n",
    "min_max_dates = compustat.reset_index(level='date').groupby(level='permno').agg(min_date=('date', 'min'), max_date=('date', 'max'))\n",
    "\n",
    "# Create list for multi-index to cover all months for each firm\n",
    "multi_index_list = []\n",
    "\n",
    "for index, row in min_max_dates.iterrows():\n",
    "    months_range = pd.date_range(start=row['min_date'], end=row['max_date'], freq='MS')\n",
    "    for month in months_range:\n",
    "        multi_index_list.append((index, month))\n",
    "\n",
    "new_index = pd.MultiIndex.from_tuples(multi_index_list, names=['permno', 'date'])\n",
    "compustat = compustat.reindex(new_index)\n",
    "\n",
    "print('Data without shifting and ffill')\n",
    "display(compustat.tail(25))\n",
    "# we want to lag data by six months (so that if a firm's fiscal year ends in December, we see this info next June)\n",
    "# we also want to forward-fill data. If we forward fill exactly 11 months we'd cover all months until the next fiscal year end\n",
    "# however, Compustat data might have gaps, so I forward fill by 23 months (it'll cover one missed annual report)\n",
    "\n",
    "compustat = compustat.groupby(level='permno').shift(6).ffill(limit=23)\n",
    "print('Data after shifting and ffill')\n",
    "display(compustat.tail(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Compustat data with CRSP and pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_crsp = cs_crsp.merge(compustat, left_index=True, right_index=True, how='left')\n",
    "display(cs_crsp.tail(12))\n",
    "\n",
    "cs_crsp.to_pickle('/home/jovyan/data/cs_crsp.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"text-align: center; font-family: 'Georgia', sans-serif; font-size: 36px; font-weight: bold; color: red;\">\n",
    "    Define three functions for replicating academic factors and analyzing returns\n",
    "</div>\n",
    "\n",
    "\n",
    "## Function 1: Assign stocks into portfolios based breakpoints\n",
    "\n",
    "- I let the function take in a bunch of inputs so that we can be flexible to create all kinds of factors\n",
    "Note:\n",
    "\n",
    "- Fama and French update their portfolio sorts only in June\n",
    "- If we do similar \"annual\" sorts:\n",
    "  - Set non-June assignments to zero\n",
    "  - Copy previous groups assignment forward to fill non-June months\n",
    "  \n",
    "## Function 2: Assign compute portfolio returns for sorts define in 'sort_groups'\n",
    "\n",
    "This function computes value-weighted portfolio returns   \n",
    "\n",
    "## Function 3: Analysis function for measuring Sharpe ratios \n",
    "\n",
    "- This is from the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_sort(df=None, col=None, percentiles=None, id_col=None, annual=True):\n",
    "    sortvar = df.loc[df['exchcd']==1, col]\n",
    "    \n",
    "    df[id_col] = np.nan  \n",
    "    group_id = 1\n",
    "    grp = sortvar.dropna().groupby(level='date')\n",
    "    \n",
    "    for pct in percentiles:\n",
    "        breakpoint = grp.apply(lambda x: np.percentile(x, pct))\n",
    "        breakpoint.name = 'breakpoint'\n",
    "        df_merged = df.merge(breakpoint, left_on='date', right_index=True, how='left')\n",
    "        assigned = df_merged[id_col].isnull() & (df_merged[col] <= df_merged['breakpoint'])         \n",
    "        df.loc[assigned[assigned].index, id_col] = group_id\n",
    "        group_id += 1\n",
    "    \n",
    "    # assign firms to to the right from the last breakpoint into a group \n",
    "    assigned = df_merged[id_col].isnull() & (df_merged[col] > df_merged['breakpoint']) \n",
    "    df.loc[assigned[assigned].index, id_col] = group_id\n",
    "    \n",
    "    if annual:\n",
    "        nonJune = df.index.get_level_values(level='date').month != 6\n",
    "        df.loc[nonJune, id_col] = np.nan\n",
    "        df[id_col] = df.groupby(level='permno')[id_col].ffill(limit=11)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_portfolio_returns(df=None, sort_groups=None):\n",
    "    \n",
    "    display(df.shape)\n",
    "\n",
    "    df['retnm'] = df['ret'].groupby(level='permno').shift(-1)\n",
    "    df['me_x_retnm'] = df['me'] * df['retnm']\n",
    "\n",
    "    # require me, sort variables, and return next month\n",
    "    ok = df['me'].notnull()\n",
    "    for required_var in ['retnm'] + sort_variables:\n",
    "        ok = ok & df[required_var].notnull()\n",
    "    df = df[ok]\n",
    "\n",
    "    display(df.shape)\n",
    "\n",
    "    sums = df.reset_index().groupby(by=['date'] + sort_groups)[['me', 'me_x_retnm']].sum()\n",
    "    portfolio_returns = sums['me_x_retnm'] / sums['me']\n",
    "    portfolio_returns = portfolio_returns.unstack(level=sort_groups)\n",
    "    \n",
    "    # because we used return as of NEXT MONTH, undo the timing so that the date in the index corresponds to the return realization\n",
    "    portfolio_returns = portfolio_returns.shift(1)\n",
    "    \n",
    "    return portfolio_returns\n",
    "\n",
    "\n",
    "def analyze_returns(r=None, name=None, start_date='1964-01', end_date='2023-09'):\n",
    "    r = r.loc[start_date:end_date]\n",
    "    ir = np.sqrt(12) * r.mean() / r.std()\n",
    "    print(f'Start: {start_date}, End: {end_date}')\n",
    "    print(f'Sharpe ratio: {ir:.2f}')\n",
    "    r.cumsum().plot(title=f'Analysis of a strategy: \"{name}\"', figsize=(12,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"text-align: center; font-family: 'Georgia', sans-serif; font-size: 36px; font-weight: bold; color: red;\">\n",
    "    Fama-French Value Factors (HML)\n",
    "</div>\n",
    "\n",
    "- With the functions I defined above, I just need to define\n",
    "  - What variable is our signal\n",
    "    - book value of equity-to-market value of equity (```beme''')\n",
    "  - What percentiles do we use for size and book-to-market sorts?\n",
    "    - Fama and French use the ```50``` percentile for size and ```30```th and ```70```th percentiles for signal variable\n",
    "  - Do we re-sort only annually at the end of June? \n",
    "    - Fama and French re-sort annually\n",
    "\n",
    "Fama and French's portfolio is constructed by assigning stocks into six portfolios: small-value, small-neutral, small-growth, big-value,...\n",
    "\n",
    "The return on HML is then:\n",
    "\n",
    "```HML = (1/2) * (small-value + big-value) - (1/2) * (small-growth + big-growth)```\n",
    "\n",
    "#### Notes on the code below:\n",
    "\n",
    "- I create a list ```sort_variables``` to indicate by which variables I sort\n",
    "- I create a dictionary percentiles (with the sort variables as keys) to indicate what breakpoints I want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from the original data (we will modify it)\n",
    "cs_crsp = pd.read_pickle('/home/jovyan/data/cs_crsp.pkl')\n",
    "\n",
    "# construct BE/ME - set firms with negative BEs to missing\n",
    "cs_crsp['beme'] = cs_crsp['be'] / cs_crsp['me']\n",
    "cs_crsp['beme'] = cs_crsp.groupby(level='permno')['beme'].shift(24)\n",
    "\n",
    "negative_be = cs_crsp['be'] < 0\n",
    "cs_crsp.loc[negative_be, 'beme'] = np.nan\n",
    "\n",
    "sort_variables = ['me', 'beme']\n",
    "percentiles = {'me': [50],\n",
    "              'beme': [30, 70]}\n",
    "\n",
    "for sortvar in sort_variables:\n",
    "    cs_crsp = portfolio_sort(df=cs_crsp, col=sortvar, percentiles=percentiles[sortvar], id_col=sortvar + '_group', annual=True)\n",
    "    \n",
    "sort_groups = [sortvar + '_group' for sortvar in sort_variables]\n",
    "\n",
    "portfolio_returns = compute_portfolio_returns(cs_crsp, sort_groups=sort_groups)\n",
    "\n",
    "hml = portfolio_returns.loc[:,[(1,3), (2,3)]].mean(axis=1) - portfolio_returns.loc[:,[(1,1), (2,1)]].mean(axis=1)\n",
    "hml.name = 'hml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_returns(hml, 'Our HML', end_date='2007-06')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Fama and French data from the pickle file we created previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_data = pd.read_pickle('/home/jovyan/data/ff_data.pkl')\n",
    "ff_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.concat([hml, ff_data], axis=1).dropna()\n",
    "merged_data[['hml', 'Mkt-RF', 'SMB', 'HML']].corr().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"text-align: center; font-family: 'Georgia', sans-serif; font-size: 36px; font-weight: bold; color: red;\">\n",
    "    Carhart's Momentum Factor (UMD)\n",
    "</div>\n",
    "\n",
    "Momentum in stock returns is typically defined by sorting on stocks returns from month t-12 to month t-2 \n",
    "\n",
    "I construct the equivalent of the Fama and French's UMD (which is Carhart's ```PR1YR```) factor\n",
    "\n",
    "Note: This factor is rebalanced monthly, and so I set annual=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from the original data (we will modify it)\n",
    "cs_crsp = pd.read_pickle('/home/jovyan/data/cs_crsp.pkl')\n",
    "\n",
    "cs_crsp['r12_2'] = cs_crsp['ret'].rolling(window=11).sum().shift(1)\n",
    "cs_crsp['r12_2_count'] = cs_crsp['ret'].rolling(window=11).count().shift(1)\n",
    "\n",
    "# set to missing if fewer than 6 obs -- newer versions of Pandas could also do ...rolling(window=11).sum(min_count=6)...\n",
    "not_ok = cs_crsp['r12_2_count'] < 6\n",
    "cs_crsp.loc[not_ok, 'r12_2'] = np.nan\n",
    "\n",
    "sort_variables = ['me', 'r12_2']\n",
    "percentiles = {'me': [50],\n",
    "              'r12_2': [30, 70]}\n",
    "\n",
    "for sortvar in sort_variables:\n",
    "    cs_crsp = portfolio_sort(df=cs_crsp, col=sortvar, percentiles=percentiles[sortvar], id_col=sortvar + '_group', annual=False)\n",
    "    \n",
    "sort_groups = [sortvar + '_group' for sortvar in sort_variables]\n",
    "\n",
    "portfolio_returns = compute_portfolio_returns(cs_crsp, sort_groups=sort_groups)\n",
    "\n",
    "umd = portfolio_returns.loc[:,[(1,3), (2,3)]].mean(axis=1) - portfolio_returns.loc[:,[(1,1), (2,1)]].mean(axis=1)\n",
    "umd = umd.shift(1)\n",
    "umd.name = 'umd'\n",
    "analyze_returns(umd, 'Momentum Factor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"text-align: center; font-family: 'Georgia', sans-serif; font-size: 36px; font-weight: bold; color: red;\">\n",
    "    Measuring Alphas\n",
    "</div>\n",
    "\n",
    "We measure alphas by\n",
    "\n",
    "```Running a linear regression of strategy returns against some factors```\n",
    "\n",
    "- In CAPM there is only one factor on the RHS: MKTRF\n",
    "- In the Fama-French three-factor model, there are three factors: MKTRF, SMB, and HML\n",
    "- In the Fama-French five-factor model, there are three factors: MKTRF, SMB, HML, RMW, and CMA\n",
    "\n",
    "**Alphas** measure stocks', managers', or strategies' *abnormal* returns\n",
    "\n",
    "That is, how profitable an investment is when we 'expunge' from returns any exposures to the factors of the factor model\n",
    "\n",
    "Notes:\n",
    "\n",
    "- I use statsmodels.api for running the linear regression\n",
    "  - This is a well-known (and well-maintained) package\n",
    "  - The benefit of this package is that it gives a nice, easy summary of the results\n",
    "- Other packages, such as sklearn, are better for estimating more complex models\n",
    "  - They don't provide similar summary statistics -- because such summary statistics are often hard to compute for more complicated models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "regression_data = pd.concat([umd, ff_data], axis=1).dropna()\n",
    "\n",
    "y = regression_data['umd']\n",
    "X = regression_data[['Mkt-RF', 'SMB', 'HML']]\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Create a model. This is an OBJECT that comes with methods. We are NOT estimating the model yet, just creating it.\n",
    "model = sm.OLS(y, X)\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print the summary\n",
    "display(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question:\n",
    "\n",
    "What if we repeat this computation for our HML factor?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
